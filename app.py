# =========================
# config
# =========================
import os
import re
from dataclasses import dataclass
from typing import Optional, List

from dotenv import load_dotenv
load_dotenv()  # ãƒ­ãƒ¼ã‚«ãƒ«ã® .env ã‚’èª­ã‚€

import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import SystemMessage, HumanMessage
from langchain_community.vectorstores import Chroma

# è¿½åŠ : Chroma ã‚’ãƒ¡ãƒ¢ãƒªã§ä½¿ã†ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
import chromadb
from chromadb.config import Settings


@dataclass
class Config:
    app_name: str = "streamlit-llm-app"
    model_name: str = "gpt-4o-mini"
    temperature: float = 0.0
    embed_model: str = "text-embedding-3-small"
    top_k: int = 3


# =========================
# utils
# =========================
def slugify_ascii(text: str) -> str:
    """ASCII/slugåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®‰å…¨åŒ–ï¼‰"""
    text = text.lower()
    text = re.sub(r"[^a-z0-9]+", "-", text)
    return re.sub(r"-+", "-", text).strip("-")


def build_llm(cfg: Config) -> ChatOpenAI:
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    return ChatOpenAI(model_name=cfg.model_name, temperature=cfg.temperature)


def resolve_api_key_or_error() -> Optional[str]:
    """ENVâ†’Secretsã®é †ã§APIã‚­ãƒ¼ã‚’å–å¾—ã—ã€è¦‹ã¤ã‹ã‚Œã°ENVã«ã‚‚æ³¨å…¥"""
    key = os.getenv("OPENAI_API_KEY")
    if key:
        return key
    try:
        key = st.secrets.get("OPENAI_API_KEY")  # Secrets ã® TOML ãŒå£Šã‚Œã¦ã„ã‚‹ã¨ä¾‹å¤–
    except Exception:
        st.error(
            "Streamlit Secrets ã®æ§‹æ–‡ï¼ˆTOMLï¼‰ãŒä¸æ­£ã§ã™ã€‚æ¬¡ã®å½¢å¼ã«ç›´ã—ã¦ãã ã•ã„ï¼š\n\n"
            '```\nOPENAI_API_KEY = "sk-xxxxxxxx"\n```'
        )
        return None
    if key:
        os.environ["OPENAI_API_KEY"] = key
        return key
    return None


# =========================
# stores
# =========================
def build_vectorstore(cfg: Config) -> Chroma:
    """Chroma ã‚’ã‚¨ãƒ•ã‚§ãƒ¡ãƒ©ãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªï¼‰ã§åˆæœŸåŒ–ã—ã€è»½é‡ã®æ–¹é‡ãƒ†ã‚­ã‚¹ãƒˆã‚’æ ¼ç´"""
    texts = [
        "persona:A æ–¹é‡: ã‚ãªãŸã¯æ—¥æœ¬ã®åŠ´å‹™ãƒ»å°±æ¥­è¦å‰‡ã®ä¸€èˆ¬çš„ãªåŠ©è¨€è€…ã€‚ä¸€æ¬¡æƒ…å ±ã®ç¢ºèªã‚’ä¿ƒã—ã€å€‹åˆ¥ã®æ³•çš„åŠ©è¨€ã¯é¿ã‘ã€å®Ÿå‹™ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚„ç›¸è«‡å…ˆã‚’ææ¡ˆã™ã‚‹ã€‚",
        "persona:B æ–¹é‡: ã‚ãªãŸã¯Python/ç”ŸæˆAIã®æ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€‚å°ã•ãä½œã£ã¦æ¤œè¨¼ã€å†ç¾æ€§ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€APIã‚­ãƒ¼ç®¡ç†ã«é…æ…®ã—ã€ç°¡æ½”ãªæ‰‹é †ã‚’ç¤ºã™ã€‚",
    ]
    metadatas = [{"persona": "A"}, {"persona": "B"}]
    embeddings = OpenAIEmbeddings(model=cfg.embed_model)

    # â˜…ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼šæ°¸ç¶šåŒ–ã‚’ä½¿ã‚ãšã€SQLite ä¾å­˜ã‚’é¿ã‘ã‚‹
    client = chromadb.EphemeralClient(
        Settings(is_persistent=False, anonymized_telemetry=False)
    )
    # persist_directory ã‚’æ¸¡ã•ãªã„ & client ã‚’æ˜ç¤º
    vs = Chroma.from_texts(
        texts=texts,
        embedding=embeddings,
        metadatas=metadatas,
        client=client,
        collection_name=f"persona-{slugify_ascii(cfg.app_name)}",
    )
    return vs


def build_retriever(cfg: Config):
    """VectorStoreã‹ã‚‰Retrieverã‚’ç”Ÿæˆ"""
    vs = build_vectorstore(cfg)
    return vs.as_retriever(search_kwargs={"k": cfg.top_k})


# =========================
# indexing
# =========================
def retrieve_context(query: str, persona: str, retriever) -> List[str]:
    """ã‚¯ã‚¨ãƒªï¼‹ãƒšãƒ«ã‚½ãƒŠã§é–¢é€£æ–‡è„ˆã‚’å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯ç©ºãƒªã‚¹ãƒˆï¼‰"""
    try:
        docs = retriever.get_relevant_documents(query)
        selected = [d.page_content for d in docs if d.metadata.get("persona") == persona]
        return selected or [d.page_content for d in docs]
    except Exception:
        return []


# =========================
# tools
# =========================
def make_system_prompt(persona: str, contexts: Optional[List[str]] = None) -> str:
    """ãƒšãƒ«ã‚½ãƒŠåˆ¥ã®Systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã€è£œåŠ©æ–‡è„ˆã‚’ä»˜åŠ """
    persona_map = {
        "A": (
            "You are a Japanese labor/HR compliance advisor. "
            "Provide general, practical, and safe guidance. "
            "For legal decisions, encourage users to check official sources or consult professionals."
        ),
        "B": (
            "You are a Python & Generative AI productivity engineer. "
            "Propose small testable steps, concise examples, and consider security & reproducibility."
        ),
    }
    base = persona_map.get(persona, "You are a helpful assistant.")
    ctx = ""
    if contexts:
        ctx = "\n\n# Additional context (persona policy)\n" + "\n".join(f"- {c}" for c in contexts)
    return base + ctx


# =========================
# agent
# =========================
def generate_response(
    user_text: str,
    persona_value: str,
    llm: ChatOpenAI,
    retriever=None,
) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ã‚¸ã‚ªé¸æŠã‚’å—ã‘å–ã‚Šã€LLMã®å›ç­”æ–‡å­—åˆ—ã‚’è¿”ã™"""
    try:
        if not user_text.strip():
            return "å…¥åŠ›ãŒç©ºã§ã™ã€‚ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

        persona = "A" if persona_value.startswith("A") else "B"
        contexts = retrieve_context(user_text, persona, retriever) if retriever else []
        system_prompt = make_system_prompt(persona, contexts)

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_text),
        ]
        result = llm.invoke(messages)  # LangChain v0.2+ ã®æ¨å¥¨å‘¼ã³å‡ºã—
        return result.content or "ï¼ˆLLMã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã‚Šã¾ã—ãŸï¼‰"

    except Exception as e:
        msg = str(e)
        if "OPENAI_API_KEY" in msg or "api key" in msg.lower():
            return "OpenAI APIã‚­ãƒ¼ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚.env ã¾ãŸã¯ Secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        if "rate limit" in msg.lower():
            return "ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        if "timeout" in msg.lower():
            return "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ¥ç¶šç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã®æ¨æ¸¬: {msg}"


# =========================
# app (Streamlit)
# =========================
def run_app():
    """Streamlit UI æœ¬ä½“"""
    st.set_page_config(page_title="LLMã‚¢ãƒ—ãƒªï¼ˆLangChain + Streamlitï¼‰", page_icon="ğŸ¤–", layout="centered")

    st.title("LLMã‚¢ãƒ—ãƒªï¼ˆLangChain + Streamlitï¼‰")
    st.caption("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ç›¸è«‡å†…å®¹ã‚’è¨˜å…¥ã—ã€å°‚é–€å®¶A/Bã‚’é¸ã‚“ã§é€ä¿¡ã—ã¦ãã ã•ã„ã€‚LangChainçµŒç”±ã§LLMãŒå›ç­”ã—ã¾ã™ã€‚")

    with st.expander("ã“ã®ã‚¢ãƒ—ãƒªã®æ¦‚è¦ / æ“ä½œæ–¹æ³•", expanded=True):
        st.markdown(
            "- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã¯1ã¤ã§ã™ã€‚\n"
            "- ãƒ©ã‚¸ã‚ªã§ **å°‚é–€å®¶ã‚¿ã‚¤ãƒ—** ã‚’é¸æŠï¼ˆA: åŠ´å‹™ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ / B: æ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼‰ã€‚\n"
            "- é¸æŠã«å¿œã˜ã¦ System ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ›¿ãˆã€LLMã«æŠ•ã’ã¾ã™ã€‚\n"
            "- ãƒ­ãƒ¼ã‚«ãƒ«ã¯ `.env`ã€Cloudã¯ **Secrets** ã« `OPENAI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    # APIã‚­ãƒ¼è§£æ±ºï¼ˆENV or Secretsï¼‰
    api_key = resolve_api_key_or_error()
    if not api_key:
        st.stop()

    cfg = Config()
    try:
        llm = build_llm(cfg)
    except Exception as e:
        st.error(f"LLMåˆæœŸåŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    retriever = None
    try:
        retriever = build_retriever(cfg)  # â˜…ãƒ¡ãƒ¢ãƒªChromaã§åˆæœŸåŒ–ï¼ˆSQLiteä¾å­˜ãªã—ï¼‰
    except Exception as e:
        st.warning(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆRAGãªã—ã§ç¶™ç¶šï¼‰: {e}")

    persona = st.radio(
        "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ",
        options=["Aï½œåŠ´å‹™ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼", "Bï½œæ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"],
        horizontal=True,
    )
    user_text = st.text_area("ç›¸è«‡å†…å®¹ï¼ˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼‰", height=160, placeholder="ä¾‹ï¼š36å”å®šã®é‹ç”¨ãƒã‚¤ãƒ³ãƒˆ / å°ã•ãªè‡ªå‹•åŒ–ã®å§‹ã‚æ–¹")
    if st.button("é€ä¿¡"):
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            answer = generate_response(user_text, persona, llm, retriever)
        st.markdown("### å›ç­”")
        st.write(answer)


# =========================
# mainï¼ˆStreamlitã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼‰
# =========================
if __name__ == "__main__":
    run_app()
