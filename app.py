# =========================
# config
# =========================
import os
import re
from dataclasses import dataclass
from typing import Optional, List

from dotenv import load_dotenv
load_dotenv()  # ãƒ­ãƒ¼ã‚«ãƒ« .env èª­ã¿è¾¼ã¿

import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import SystemMessage, HumanMessage, Document  # Documentã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã«ä½¿ç”¨


@dataclass
class Config:
    app_name: str = "streamlit-llm-app"
    model_name: str = "gpt-4o-mini"
    temperature: float = 0.0
    embed_model: str = "text-embedding-3-small"
    top_k: int = 3


# =========================
# utils
# =========================
def slugify_ascii(text: str) -> str:
    """ASCII/slugåŒ–ï¼ˆãƒ‘ã‚¹å®‰å…¨åŒ–ï¼‰"""
    text = text.lower()
    text = re.sub(r"[^a-z0-9]+", "-", text)
    return re.sub(r"-+", "-", text).strip("-")


def build_llm(cfg: Config) -> ChatOpenAI:
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆ"""
    return ChatOpenAI(model_name=cfg.model_name, temperature=cfg.temperature)


def resolve_api_key_or_error() -> Optional[str]:
    """ENVâ†’Secretsã®é †ã§APIã‚­ãƒ¼ã‚’å–å¾—ã—ã€è¦‹ã¤ã‹ã‚Œã°ENVã«ã‚‚æ³¨å…¥"""
    key = os.getenv("OPENAI_API_KEY")
    if key:
        return key
    try:
        key = st.secrets.get("OPENAI_API_KEY")  # Secretsã®TOMLä¸æ­£ã ã¨ä¾‹å¤–
    except Exception:
        st.error(
            "Streamlit Secrets ã®æ§‹æ–‡ï¼ˆTOMLï¼‰ãŒä¸æ­£ã§ã™ã€‚ä»¥ä¸‹ã®å½¢å¼ã«ç›´ã—ã¦ãã ã•ã„ï¼š\n\n"
            '```\nOPENAI_API_KEY = "sk-xxxxxxxx"\n```'
        )
        return None
    if key:
        os.environ["OPENAI_API_KEY"] = key
        return key
    return None


# =========================
# stores
# =========================
class SimpleInMemoryRetriever:
    """ChromaãŒä½¿ãˆãªã„ç’°å¢ƒå‘ã‘ã®ç°¡æ˜“ãƒ™ã‚¯ã‚¿æ¤œç´¢ï¼ˆOpenAIåŸ‹ã‚è¾¼ã¿ + ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼‰"""
    def __init__(self, texts: List[str], metadatas: List[dict], embeddings: OpenAIEmbeddings, k: int = 3):
        self.embeddings = embeddings
        self.docs = [Document(page_content=t, metadata=m) for t, m in zip(texts, metadatas)]
        self.vectors = embeddings.embed_documents(texts)
        self.k = k

    def _cosine(self, u: List[float], v: List[float]) -> float:
        # numpyãªã—ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        dot = sum(a * b for a, b in zip(u, v))
        nu = sum(a * a for a in u) ** 0.5
        nv = sum(b * b for b in v) ** 0.5
        return dot / (nu * nv + 1e-10)

    def get_relevant_documents(self, query: str) -> List[Document]:
        qv = self.embeddings.embed_query(query)
        scored = [(self._cosine(qv, vec), i) for i, vec in enumerate(self.vectors)]
        scored.sort(reverse=True)
        top = scored[: self.k]
        return [self.docs[i] for _, i in top]


def build_retriever(cfg: Config):
    """å¯èƒ½ãªã‚‰Chroma(ã‚¨ãƒ•ã‚§ãƒ¡ãƒ©ãƒ«)ã‚’ä½¿ç”¨ã€‚ãƒ€ãƒ¡ãªã‚‰ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªæ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    texts = [
        "persona:A æ–¹é‡: ã‚ãªãŸã¯æ—¥æœ¬ã®åŠ´å‹™ãƒ»å°±æ¥­è¦å‰‡ã®ä¸€èˆ¬çš„ãªåŠ©è¨€è€…ã€‚ä¸€æ¬¡æƒ…å ±ã®ç¢ºèªã‚’ä¿ƒã—ã€å€‹åˆ¥ã®æ³•çš„åŠ©è¨€ã¯é¿ã‘ã€å®Ÿå‹™ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚„ç›¸è«‡å…ˆã‚’ææ¡ˆã™ã‚‹ã€‚",
        "persona:B æ–¹é‡: ã‚ãªãŸã¯Python/ç”ŸæˆAIã®æ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€‚å°ã•ãä½œã£ã¦æ¤œè¨¼ã€å†ç¾æ€§ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€APIã‚­ãƒ¼ç®¡ç†ã«é…æ…®ã—ã€ç°¡æ½”ãªæ‰‹é †ã‚’ç¤ºã™ã€‚",
    ]
    metadatas = [{"persona": "A"}, {"persona": "B"}]
    embeddings = OpenAIEmbeddings(model=cfg.embed_model)

    # --- ã¾ãšChromaã‚’è©¦ã™ï¼ˆimportæ®µéšã§è½ã¡ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚é–¢æ•°å†…ã§tryï¼‰ ---
    try:
        import chromadb
        from chromadb.config import Settings
        from langchain_community.vectorstores import Chroma

        client = chromadb.EphemeralClient(Settings(is_persistent=False, anonymized_telemetry=False))
        vs = Chroma.from_texts(
            texts=texts,
            embedding=embeddings,
            metadatas=metadatas,
            client=client,
            collection_name=f"persona-{slugify_ascii(cfg.app_name)}",
        )
        return vs.as_retriever(search_kwargs={"k": cfg.top_k})
    except Exception as e:
        # Cloudã§SQLiteãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤ã„ç­‰ã®ç†ç”±ã§å¤±æ•— â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.warning(f"Chromaã‚’åˆ©ç”¨ã§ããªã„ãŸã‚ã€ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªæ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™: {e}")
        return SimpleInMemoryRetriever(texts, metadatas, embeddings, k=cfg.top_k)


# =========================
# indexing
# =========================
def retrieve_context(query: str, persona: str, retriever) -> List[str]:
    """ã‚¯ã‚¨ãƒªï¼‹ãƒšãƒ«ã‚½ãƒŠã§é–¢é€£æ–‡è„ˆã‚’å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯ç©ºãƒªã‚¹ãƒˆï¼‰"""
    try:
        docs = retriever.get_relevant_documents(query)
        selected = [d.page_content for d in docs if d.metadata.get("persona") == persona]
        return selected or [d.page_content for d in docs]
    except Exception:
        return []


# =========================
# tools
# =========================
def make_system_prompt(persona: str, contexts: Optional[List[str]] = None) -> str:
    """ãƒšãƒ«ã‚½ãƒŠåˆ¥ã®Systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã€è£œåŠ©æ–‡è„ˆã‚’ä»˜åŠ """
    persona_map = {
        "A": (
            "You are a Japanese labor/HR compliance advisor. "
            "Provide general, practical, and safe guidance. "
            "For legal decisions, encourage users to check official sources or consult professionals."
        ),
        "B": (
            "You are a Python & Generative AI productivity engineer. "
            "Propose small testable steps, concise examples, and consider security & reproducibility."
        ),
    }
    base = persona_map.get(persona, "You are a helpful assistant.")
    ctx = ""
    if contexts:
        ctx = "\n\n# Additional context (persona policy)\n" + "\n".join(f"- {c}" for c in contexts)
    return base + ctx


# =========================
# agent
# =========================
def generate_response(
    user_text: str,
    persona_value: str,
    llm: ChatOpenAI,
    retriever=None,
) -> str:
    """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ã‚¸ã‚ªé¸æŠã‚’å—ã‘å–ã‚Šã€LLMã®å›ç­”æ–‡å­—åˆ—ã‚’è¿”ã™"""
    try:
        if not user_text.strip():
            return "å…¥åŠ›ãŒç©ºã§ã™ã€‚ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

        persona = "A" if persona_value.startswith("A") else "B"
        contexts = retrieve_context(user_text, persona, retriever) if retriever else []
        system_prompt = make_system_prompt(persona, contexts)

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_text),
        ]
        result = llm.invoke(messages)  # LangChain v0.2+ ã®æ¨å¥¨å‘¼ã³å‡ºã—
        return result.content or "ï¼ˆLLMã‹ã‚‰ç©ºã®å¿œç­”ãŒè¿”ã‚Šã¾ã—ãŸï¼‰"

    except Exception as e:
        msg = str(e)
        if "OPENAI_API_KEY" in msg or "api key" in msg.lower():
            return "OpenAI APIã‚­ãƒ¼ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚.env ã¾ãŸã¯ Secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        if "rate limit" in msg.lower():
            return "ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        if "timeout" in msg.lower():
            return "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ¥ç¶šç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã®æ¨æ¸¬: {msg}"


# =========================
# app (Streamlit)
# =========================
def run_app():
    """Streamlit UI æœ¬ä½“"""
    st.set_page_config(page_title="LLMã‚¢ãƒ—ãƒªï¼ˆLangChain + Streamlitï¼‰", page_icon="ğŸ¤–", layout="centered")

    st.title("LLMã‚¢ãƒ—ãƒªï¼ˆLangChain + Streamlitï¼‰")
    st.caption("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ç›¸è«‡å†…å®¹ã‚’è¨˜å…¥ã—ã€å°‚é–€å®¶A/Bã‚’é¸ã‚“ã§é€ä¿¡ã—ã¦ãã ã•ã„ã€‚LangChainçµŒç”±ã§LLMãŒå›ç­”ã—ã¾ã™ã€‚")

    with st.expander("ã“ã®ã‚¢ãƒ—ãƒªã®æ¦‚è¦ / æ“ä½œæ–¹æ³•", expanded=True):
        st.markdown(
            "- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã¯1ã¤ã§ã™ã€‚\n"
            "- ãƒ©ã‚¸ã‚ªã§ **å°‚é–€å®¶ã‚¿ã‚¤ãƒ—** ã‚’é¸æŠï¼ˆA: åŠ´å‹™ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ / B: æ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼‰ã€‚\n"
            "- é¸æŠã«å¿œã˜ã¦ System ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ›¿ãˆã€LLMã«æŠ•ã’ã¾ã™ã€‚\n"
            "- ãƒ­ãƒ¼ã‚«ãƒ«ã¯ `.env`ã€Cloudã¯ **Secrets** ã« `OPENAI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    # APIã‚­ãƒ¼è§£æ±ºï¼ˆENV or Secretsï¼‰
    api_key = resolve_api_key_or_error()
    if not api_key:
        st.stop()

    cfg = Config()
    try:
        llm = build_llm(cfg)
    except Exception as e:
        st.error(f"LLMåˆæœŸåŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    retriever = None
    try:
        retriever = build_retriever(cfg)  # Chroma or ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«è‡ªå‹•åˆ‡æ›¿
    except Exception as e:
        st.warning(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆRAGãªã—ã§ç¶™ç¶šï¼‰: {e}")

    persona = st.radio(
        "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ",
        options=["Aï½œåŠ´å‹™ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼", "Bï½œæ¥­å‹™æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"],
        horizontal=True,
    )
    user_text = st.text_area("ç›¸è«‡å†…å®¹ï¼ˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼‰", height=160, placeholder="ä¾‹ï¼š36å”å®šã®é‹ç”¨ãƒã‚¤ãƒ³ãƒˆ / å°ã•ãªè‡ªå‹•åŒ–ã®å§‹ã‚æ–¹")
    if st.button("é€ä¿¡"):
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            answer = generate_response(user_text, persona, llm, retriever)
        st.markdown("### å›ç­”")
        st.write(answer)


# =========================
# mainï¼ˆStreamlitã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼‰
# =========================
if __name__ == "__main__":
    run_app()
