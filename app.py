# =========================
# config: ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
# =========================
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# .envã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


# =========================
# utils: æ±ç”¨é–¢æ•°
# =========================
def error_message(msg: str) -> str:
    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™é–¢æ•°
    return f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {msg}"


# =========================
# stores: DBé–¢é€£ï¼ˆä»Šå›ã¯æœªä½¿ç”¨ï¼‰
# =========================
def init_store():
    # ä»Šå›ã¯ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ä½¿ã‚ãªã„ã®ã§ãƒ€ãƒŸãƒ¼
    return None


# =========================
# indexing: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç†ï¼ˆæœªä½¿ç”¨ï¼‰
# =========================
def build_index():
    # ä»Šå›ã¯æœªä½¿ç”¨
    return None


# =========================
# tools: LLMå‘¼ã³å‡ºã—ç”¨
# =========================
def call_llm(user_input: str, expert: str, llm: ChatOpenAI) -> str:
    # å°‚é–€å®¶ã”ã¨ã«systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
    if expert == "å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼":
        system_prompt = "You are a professional psychological counselor. Provide empathetic and supportive advice."
    elif expert == "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        system_prompt = "You are a skilled business consultant. Provide practical and strategic advice for management issues."
    else:
        return error_message("é¸æŠã—ãŸå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ãŒä¸æ˜ã§ã™ã€‚")

    try:
        # LangChainã®Chatãƒ¢ãƒ‡ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã™
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_input),
        ]
        result = llm(messages)
        return result.content
    except Exception as e:
        return error_message(f"LLMå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


# =========================
# agent: å…¥åŠ›å€¤ã‚’å—ã‘ã¦å‡¦ç†
# =========================
def agent_process(user_input: str, expert: str) -> str:
    # LLMã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
    try:
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
    except Exception as e:
        return error_message(f"LLMåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    return call_llm(user_input, expert, llm)


# =========================
# app: Streamlit UIæ§‹ç¯‰
# =========================
def main():
    st.title("ğŸ§  LLMã‚¢ãƒ—ãƒª: å°‚é–€å®¶ã«ç›¸è«‡ã—ã‚ˆã†")

    # ã‚¢ãƒ—ãƒªã®èª¬æ˜æ–‡
    st.write("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€å…¥åŠ›ã—ãŸç›¸è«‡å†…å®¹ã‚’LLMã«æ¸¡ã—ã€")
    st.write("å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ ã¾ãŸã¯ çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ ã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚")
    st.write("ä¸‹è¨˜ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼ˆå°‚é–€å®¶ã®é¸æŠï¼‰
    expert = st.radio("å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„:", ["å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ"])

    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    user_input = st.text_area("ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("é€ä¿¡"):
        if not user_input.strip():
            st.warning("ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("LLMãŒè€ƒãˆã¦ã„ã¾ã™..."):
                response = agent_process(user_input, expert)
                st.success("å›ç­”:")
                st.write(response)


# =========================
# å®Ÿè¡Œä¾‹
# =========================
if __name__ == "__main__":
    main()
